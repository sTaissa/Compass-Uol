<h1 align="center"> Sprint 6</h1>

<p align="center">
 <a href="#sobre">Sobre</a> â€¢
 <a href="#anotacoes">AnotaÃ§Ãµes</a> â€¢
 <a href="#labs">LaboratÃ³rios</a>
</p>

<br> 

<a id="sobre"></a>
## ðŸ“Žâ€ŠSobre

### Mentor

[Aime Pereira](https://github.com/aimeepereira)

### Cursos e certificados

- [AWS Skill Builder - Data Analytics Fundamentals (Portuguese)](/certificados/sprint6_AWS-DataAnalytics.PNG)
- [AWS Partner: Data Analytics on AWS (Business) (Portuguese)](/certificados/sprint6_AWS-DataAnalytics-Business.PNG)
- [AWS Skill Builder - Introduction to Amazon Kinesis Streams](/certificados/sprint6_AWS-KinesisStreams.PNG)
- [AWS Skill Builder - Introduction to Amazon Kinesis Analytics](/certificados/sprint6_AWS-KinesisAnalytics.PNG)
- [AWS Skill Builder - Introduction to Amazon Elastic MapReduce (EMR) (Portuguese)](/certificados/sprint6_AWS-EMR.PNG)
- [AWS Skill Builder - Introduction to Amazon Athena (Portuguese)](/certificados/sprint6_AWS-Athena.PNG)
- [AWS Skill Builder - Introduction to Amazon Quicksight (Portuguese)](/certificados/sprint6_AWS-QuickSight.PNG)
- [AWS Skill Builder - Introduction to AWS IoT Analytics](/certificados/sprint6_AWS-IoT-Analytics.PNG)
- [AWS Skill Builder - Getting Started with Amazon Redshift](/certificados/sprint6_AWS-Redshift.PNG)
- [AWS Skill Builder - Deep Dive into Concepts and Tools for Analyzing Streaming Data (Portuguese)](/certificados/sprint6_AWS-Analysing-Streaming-Data.PNG)
- [AWS Skill Builder - Best Practices for Data Warehousing with Amazon Redshift (Portuguese)](/certificados/sprint6_AWS-DataWarehousing-with-Redshift.PNG)
- [AWS Skill Builder - Serverless Analytics (Portuguese)](/certificados/sprint6_AWS-Serverless-Analytics.PNG)
- [AWS Skill Builder - Why Analytics for Games (Portuguese)](/certificados/sprint6_AWS-AnalyticsGame.PNG)

<br>

<a id="anotacoes"></a>
## ðŸ“š AnotaÃ§Ãµes

[AnotaÃ§Ãµes sobre AWS](https://lowly-pear-52e.notion.site/AWS-a43ecbd43e974b9087488e1e3b149f2b)

<br>

<a id="labs"></a>
## ðŸ‘©â€ðŸ’»â€Š LaboratÃ³rios


### Lab AWS S3
>Explorar as capacidades do serviÃ§o AWS S3.  No passo a passo, vocÃª serÃ¡ guiado pelas configuraÃ§Ãµes necessÃ¡rias para que um bucket do Amazon S3 funcione como hospedagem de conteÃºdo estÃ¡tico.

#### Arquivos a colocar no bucket:
- [index.html](/sprint6/labs/arquivos/index.html)
- [dados/nomes.csv](/sprint6/labs/arquivos/dados/nomes.csv)
- [404.html](/sprint6/labs/arquivos/404.html)

Bucket com os arquivos pedidos e o acesso e polÃ­ticas pÃºblicas:

![bucket publico](/sprint6/labs/lab1%20bucket.PNG)

Site rodando hospedado estaticamente no S3 criado:

![site lab1](/sprint6/labs/lab1%20site.PNG)

### Lab AWS Athena
>ApÃ³s realizar o laboratÃ³rio anterior, crie uma consulta que lista os 3 nomes mais usados em cada dÃ©cada desde o 1950 atÃ© hoje usando o arquivo nomes.csv baixado anteriormente.

Query rodando no Athena apÃ³s configurar tudo:
``` SQL
WITH decadas AS (
Â Â Â  SELECT
Â Â Â Â Â Â Â  nome,Â 
Â Â Â Â Â Â Â  CONCAT(SUBSTR(CAST(ano AS VARCHAR), 1, 3), '0') AS decada, --Substitui o Ãºltimo dÃ­gito do ano por 0, para ficar por dÃ©cadas
Â Â Â Â Â Â Â  RANK() OVER(PARTITION BY CONCAT(SUBSTR(CAST(ano AS VARCHAR), 1, 3), '0') ORDER BY SUM(total) DESC, nome ASC) AS ROW --Numera as linhas separado por dÃ©cada ordenado pela soma total (nome mais usado)
Â Â Â  FROM meubanco.tabela
Â Â Â  WHERE ano BETWEEN 1950 AND 2023
Â Â Â  GROUP BY nome, CONCAT(SUBSTR(CAST(ano AS VARCHAR), 1, 3), '0') --Agrupa por nome e dÃ©cada para retirar nomes repetidos
)

SELECTÂ 
Â Â Â  nome,Â 
Â Â Â  decadaÂ 
FROM decadasÂ 
WHERE ROW IN (1,2,3)Â 
ORDER BY decada --Seleciona apenas os 3 primeiros nomes mais usados de cada dÃ©cada
```

Resultado da query:

![query1](/sprint6/labs/lab2%20resultado1.PNG)
![query2](/sprint6/labs/lab2%20resultado2.PNG)

### Lab AWS Lambda
>ApÃ³s realizar os laboratÃ³rios anteriores, execute uma funÃ§Ã£o Lambda.

#### Arquivo gerado pelo Docker para criar a camada e baixar as dependÃªncias necessÃ¡rias pra rodar a funÃ§Ã£o:
- [minha-camada-pandas.zip](/sprint6/labs/arquivos/minha-camada-pandas.zip)

ApÃ³s as configuraÃ§Ãµes, o cÃ³digo da funÃ§Ã£o:
``` Python
import json
import pandas
import boto3


def lambda_handler(event, context):
Â Â Â  s3_client = boto3.client('s3')

Â Â Â  bucket_name = 'bucket-taissa'
Â Â Â  s3_file_name = 'dados/nomes.csv'
Â Â Â  objeto = s3_client.get_object(Bucket=bucket_name, Key=s3_file_name)
Â Â Â  df=pandas.read_csv(objeto['Body'], sep=',')
Â Â Â  rows = len(df.axes[0])

Â Â Â  return {
Â Â Â Â Â Â Â  'statusCode': 200,
Â Â Â Â Â Â Â  'body': f"Este arquivo tem {rows} linhas"
Â Â Â  }
```

SaÃ­da da funÃ§Ã£o:

![saida funÃ§Ã£o](/sprint6/labs/lab3%20saida.PNG)
